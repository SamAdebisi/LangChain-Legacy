{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parsers for LLM Input / Output with LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.3.11\n",
    "# !pip install langchain-openai==0.2.12\n",
    "# !pip install langchain-community==0.3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass \n",
    "\n",
    "OPENAI_KEY = getpass('Please enter your OpenAI API key here: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup system environment variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Models and LLMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-40-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic Output Parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticOutputParser(pydantic_object=<class '__main__.QueryResponse'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "# Define your desired data structure - like a python data class \n",
    "class QueryResponse(BaseModel):\n",
    "    description: str = Field(description=\"A brief description of the topic asked by the user\")\n",
    "    pros: str = Field(description=\"3 bullet points showing the pros of the topic asked by the user\")\n",
    "    cons: str = Field(description=\"3 bullet points showing the cons of the topic asked by the user\")\n",
    "    conclusion: str = Field(\"One line conclusion of the topic asked by the user\")\n",
    "    \n",
    "# Set up a parser + inject instructions into the prompt template \n",
    "parser = PydanticOutputParser(pydantic_object=QueryResponse)\n",
    "parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"description\": {\"description\": \"A brief description of the topic asked by the user\", \"title\": \"Description\", \"type\": \"string\"}, \"pros\": {\"description\": \"3 bullet points showing the pros of the topic asked by the user\", \"title\": \"Pros\", \"type\": \"string\"}, \"cons\": {\"description\": \"3 bullet points showing the cons of the topic asked by the user\", \"title\": \"Cons\", \"type\": \"string\"}, \"conclusion\": {\"default\": \"One line conclusion of the topic asked by the user\", \"title\": \"Conclusion\", \"type\": \"string\"}}, \"required\": [\"description\", \"pros\", \"cons\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# langchain pre-generated output response formatting instructions \n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "            Answer the user query and generate the response based on the following formatting instructions \n",
    "            \n",
    "            Format Instructions: \n",
    "            {format_instructions}\n",
    "            \n",
    "            Query:\n",
    "            {query} \n",
    "            \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt, \n",
    "    input_variables=[\"query\"], \n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "prompt "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

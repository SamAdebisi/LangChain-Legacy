{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.11 in /Users/azeez/miniforge3/lib/python3.10/site-packages (0.3.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (3.11.18)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (0.3.64)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (0.3.8)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.11)\n",
      "  Using cached langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (2.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain==0.3.11) (9.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.20.0)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain==0.3.11)\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (0.28.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.11) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.11) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.11) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.11) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.2.2)\n",
      "Downloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.45\n",
      "    Uninstalling langsmith-0.3.45:\n",
      "      Successfully uninstalled langsmith-0.3.45\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.64\n",
      "    Uninstalling langchain-core-0.3.64:\n",
      "      Successfully uninstalled langchain-core-0.3.64\n",
      "Successfully installed langchain-core-0.3.63 langsmith-0.2.11\n",
      "Requirement already satisfied: langchain-openai==0.2.12 in /Users/azeez/miniforge3/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-openai==0.2.12) (0.3.63)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-openai==0.2.12) (1.77.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-openai==0.2.12) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.12.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.11.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/azeez/miniforge3/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.2.1)\n",
      "Requirement already satisfied: langchain-community==0.3.11 in /Users/azeez/miniforge3/lib/python3.10/site-packages (0.3.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (3.11.18)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.11 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (0.3.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (0.3.63)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (0.2.11)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-community==0.3.11) (9.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.28.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.11) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.11) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.11) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.11) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.11) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.11) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.33.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.2.2)\n",
      "Collecting huggingface_hub==0.26.5\n",
      "  Using cached huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.5) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.5) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.5) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.5) (2025.1.31)\n",
      "Using cached huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.32.4\n",
      "    Uninstalling huggingface-hub-0.32.4:\n",
      "      Successfully uninstalled huggingface-hub-0.32.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.2.0 requires huggingface-hub>=0.30.2, but you have huggingface-hub 0.26.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.26.5\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.3.11\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11\n",
    "!pip install huggingface_hub==0.26.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.46.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers==4.46.3) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->transformers==4.46.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->transformers==4.46.3) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->transformers==4.46.3) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->transformers==4.46.3) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# Don't run if you want to use only chatgpt\n",
    "# This is for accessing open LLMs from huggingface\n",
    "!pip install transformers==4.46.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip if only using chatgpt\n",
    "from getpass import getpass\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = getpass('Please enter your HuggingFace Token here: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "chatgpt = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain what is Generative AI in 3 bullet points\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Explain what is Generative AI in 3 bullet points\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Generative AI is a subset of artificial intelligence that focuses on creating new and original content, rather than just analyzing and processing existing data.\n",
      "\n",
      "2. It uses algorithms and machine learning techniques to generate new ideas, designs, or solutions based on a set of input data or parameters.\n",
      "\n",
      "3. Generative AI has a wide range of applications, including creating art, music, and text, as well as assisting in product design and optimization. It has the potential to revolutionize industries by automating creative tasks and providing innovative solutions.\n"
     ]
    }
   ],
   "source": [
    "response = chatgpt.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain what is Generative AI in 3 bullet points\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Explain what is Generative AI in 3 bullet points\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\\n- It uses algorithms and neural networks to generate new content that is similar to the input data it has been trained on, but with variations and creativity.\\n- Generative AI has applications in various fields, including art, design, music composition, and even creating realistic deepfake videos.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 19, 'total_tokens': 113, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5f51e9da-9b83-49bf-b424-f44ebe9b3743-0', usage_metadata={'input_tokens': 19, 'output_tokens': 94, 'total_tokens': 113, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chatgpt.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\n",
      "- It uses algorithms and neural networks to generate new content that is similar to the input data it has been trained on, but with variations and creativity.\n",
      "- Generative AI has applications in various fields, including art, design, music composition, and even creating realistic deepfake videos.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in /Users/azeez/miniforge3/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-huggingface) (0.3.63)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-huggingface) (0.20.3)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-huggingface) (4.46.3)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-huggingface) (4.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-huggingface) (0.33.4)\n",
      "Requirement already satisfied: filelock in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (2.11.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.1.post2)\n",
      "Requirement already satisfied: scikit-learn in /Users/azeez/miniforge3/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
      "Requirement already satisfied: scipy in /Users/azeez/miniforge3/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /Users/azeez/miniforge3/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (2.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.28.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2025.1.31)\n",
      "Requirement already satisfied: sympy in /Users/azeez/miniforge3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/azeez/miniforge3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Open Source LLMs with HuggingFace and LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using langchain_huggingface instead of langchain_community as per the updated langchain version 0.3\n",
    "from langchain_huggingface import HuggingFaceEndpoint \n",
    "\n",
    "# API_URL doesn't work now, so we are using repo_id of the model\n",
    "repo_id = \"microsoft/Phi-3-mini-4k-instruct\" \n",
    "\n",
    "phi3_params = {\n",
    "                  #\"wait_for_model\": True, # waits if model is not available in Hugginface serve\n",
    "                  \"do_sample\": False, # greedy decoding - temperature = 0\n",
    "                  \"return_full_text\": False, # don't return input prompt\n",
    "                  \"max_new_tokens\": 1000, # max tokens answer can go upto\n",
    "                }\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    # max_length=128,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
    "    **phi3_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain the concept of {topic} in simple terms.')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>Explain what is Generative AI in 3 bullet points<|end|>\n",
      "<|assistant|>\n"
     ]
    }
   ],
   "source": [
    "# Phi3 expects input prompt to be formatted in a specific way\n",
    "# check more details here: https://huggingface.co/microsoft/Phi-3-mini-4k-instruct\n",
    "phi3_prompt = \"\"\"<|user|>Explain what is Generative AI in 3 bullet points<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "print(phi3_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint'>\n",
      "{'wait_for_model': True}\n"
     ]
    }
   ],
   "source": [
    "print(type(llm))\n",
    "\n",
    "print(llm.model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/api/models/microsoft/Phi-3-mini-4k-instruct?expand=inferenceProviderMapping (Request ID: Root=1-687af142-0c82773569960271269d551f;4b6b7446-91a2-457b-a46a-12f5a9f35757)\n\nInvalid credentials in Authorization header",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/microsoft/Phi-3-mini-4k-instruct?expand=inferenceProviderMapping",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi3_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:389\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    386\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    387\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    401\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:766\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    764\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    765\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:973\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    960\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    961\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    971\u001b[0m         )\n\u001b[1;32m    972\u001b[0m     ]\n\u001b[0;32m--> 973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    981\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    982\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    983\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[1;32m    991\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    783\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 792\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    796\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    800\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1547\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1544\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1546\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1547\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1548\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1549\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1550\u001b[0m     )\n\u001b[1;32m   1551\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_huggingface/llms/huggingface_endpoint.py:312\u001b[0m, in \u001b[0;36mHuggingFaceEndpoint._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     response_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minvocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stop_seq \u001b[38;5;129;01min\u001b[39;00m invocation_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:2296\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2291\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI endpoint/model for text-generation is not served via TGI. Cannot return output as a stream.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pass `stream=False` as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2293\u001b[0m         )\n\u001b[1;32m   2295\u001b[0m model_id \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m-> 2296\u001b[0m provider_helper \u001b[38;5;241m=\u001b[39m \u001b[43mget_provider_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2297\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[1;32m   2298\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   2299\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m   2304\u001b[0m )\n\u001b[1;32m   2306\u001b[0m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/inference/_providers/__init__.py:190\u001b[0m, in \u001b[0;36mget_provider_helper\u001b[0;34m(provider, task, model)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying a model is required when provider is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m     provider_mapping \u001b[38;5;241m=\u001b[39m \u001b[43m_fetch_inference_provider_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     provider \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(provider_mapping))\u001b[38;5;241m.\u001b[39mprovider\n\u001b[1;32m    193\u001b[0m provider_tasks \u001b[38;5;241m=\u001b[39m PROVIDERS\u001b[38;5;241m.\u001b[39mget(provider)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/inference/_providers/_common.py:283\u001b[0m, in \u001b[0;36m_fetch_inference_provider_mapping\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03mFetch provider mappings for a model from the Hub.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi\n\u001b[0;32m--> 283\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minferenceProviderMapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m provider_mapping \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39minference_provider_mapping\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m provider_mapping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2629\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2627\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m expand\n\u001b[1;32m   2628\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m-> 2629\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2630\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   2631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/microsoft/Phi-3-mini-4k-instruct?expand=inferenceProviderMapping (Request ID: Root=1-687af142-0c82773569960271269d551f;4b6b7446-91a2-457b-a46a-12f5a9f35757)\n\nInvalid credentials in Authorization header"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(phi3_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/api/models/google/gemma-1.1-2b-it?expand=inferenceProviderMapping (Request ID: Root=1-687af1a5-238963f649fcd89f1dac0f4f;5bd29689-bf61-4bf4-8ae6-474eb51f0f9d)\n\nInvalid credentials in Authorization header",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/google/gemma-1.1-2b-it?expand=inferenceProviderMapping",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m     16\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain the concept of \u001b[39m\u001b[38;5;132;01m{topic}\u001b[39;00m\u001b[38;5;124m in simple terms.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[0;32m---> 22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformer neural networks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain/chains/base.py:606\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    607\u001b[0m         _output_key\n\u001b[1;32m    608\u001b[0m     ]\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    612\u001b[0m         _output_key\n\u001b[1;32m    613\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain/chains/llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:766\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    764\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    765\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:973\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    960\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    961\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    971\u001b[0m         )\n\u001b[1;32m    972\u001b[0m     ]\n\u001b[0;32m--> 973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    981\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    982\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    983\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[1;32m    991\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    783\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 792\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    796\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    800\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1547\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1544\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1546\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1547\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1548\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1549\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1550\u001b[0m     )\n\u001b[1;32m   1551\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/langchain_huggingface/llms/huggingface_endpoint.py:312\u001b[0m, in \u001b[0;36mHuggingFaceEndpoint._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     response_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minvocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stop_seq \u001b[38;5;129;01min\u001b[39;00m invocation_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:2296\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2291\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI endpoint/model for text-generation is not served via TGI. Cannot return output as a stream.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pass `stream=False` as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2293\u001b[0m         )\n\u001b[1;32m   2295\u001b[0m model_id \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m-> 2296\u001b[0m provider_helper \u001b[38;5;241m=\u001b[39m \u001b[43mget_provider_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2297\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[1;32m   2298\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   2299\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m   2304\u001b[0m )\n\u001b[1;32m   2306\u001b[0m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/inference/_providers/__init__.py:190\u001b[0m, in \u001b[0;36mget_provider_helper\u001b[0;34m(provider, task, model)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying a model is required when provider is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m     provider_mapping \u001b[38;5;241m=\u001b[39m \u001b[43m_fetch_inference_provider_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     provider \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(provider_mapping))\u001b[38;5;241m.\u001b[39mprovider\n\u001b[1;32m    193\u001b[0m provider_tasks \u001b[38;5;241m=\u001b[39m PROVIDERS\u001b[38;5;241m.\u001b[39mget(provider)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/inference/_providers/_common.py:283\u001b[0m, in \u001b[0;36m_fetch_inference_provider_mapping\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03mFetch provider mappings for a model from the Hub.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi\n\u001b[0;32m--> 283\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minferenceProviderMapping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m provider_mapping \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39minference_provider_mapping\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m provider_mapping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2629\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2627\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m expand\n\u001b[1;32m   2628\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m-> 2629\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2630\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   2631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/google/gemma-1.1-2b-it?expand=inferenceProviderMapping (Request ID: Root=1-687af1a5-238963f649fcd89f1dac0f4f;5bd29689-bf61-4bf4-8ae6-474eb51f0f9d)\n\nInvalid credentials in Authorization header"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"google/gemma-1.1-2b-it\"  # <- Change to any compatible model above\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    temperature=0.3,\n",
    "    max_new_tokens=512,\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain the concept of {topic} in simple terms.\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "response = chain.run(\"transformer neural networks\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_repo_id = \"google/gemma-1.1-2b-it\" \n",
    "\n",
    "gemma_params = {\n",
    "            \"wait_for_model\": True, # waits if model is not available in Hugginface serve \n",
    "            \"do_sample\": False, # greedy decoding - temperature = 0 \n",
    "            \"return_full_text\": False, # don't return input prompt \n",
    "            \"max_new_tokens\": 1000, # max tokens answer can go upto \n",
    "}\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=gemma_repo_id,\n",
    "    **gemma_params \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Local LLMs with HuggingFacePipeline API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using langchain_huggingface instead of langchain_community as per the updated langchain version 0.3 \n",
    "from langchain_huggingface import HuggingFacePipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_params = {\n",
    "            \"do_sample\": False, # greedy decoding - temperature = 0 \n",
    "            \"return_full_text\": False, # don't return input prompt \n",
    "            \"max_new_tokens\": 1000, # max tokens answer can go upto \n",
    "}\n",
    "\n",
    "local_llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"google/gemma-1.1-2b-it\", \n",
    "    task=\"text-generation\", \n",
    "    pipeline_kwargs=gemma_params, \n",
    "    # device=0      # when running on Colab selects the GPU, you can change this if you run it on your own instance if needed \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemma2B when used locally expects input prompt to be formatted in a specific way \n",
    "# check more details here: https://huggingface.co/google/gemma-1.1-2b-it#chat-template \n",
    "gemma_prompt = \"\"\"<bos><start_of_turn>user\\n\"\"\" + prompt + \"\"\"\\n<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "print(gemma_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = local_llm.invoke(gemma_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Open LLMs in HuggingFace as a Chat Model LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace \n",
    "\n",
    "chat_gemma = ChatHuggingFace(llm=llm,\n",
    "                             model_id='google/gemma-1.1-2b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Prompting with ChatGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
